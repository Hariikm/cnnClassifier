{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataIngestionConfig= namedtuple(\"IngestionConfig\", [\n",
    "    \"root_dir\",\n",
    "    \"source_URL\",\n",
    "    \"local_data_file\",\n",
    "    \"unzip_dir\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code serves the same purpose as that of the above.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The above are expirimenting for entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we go for configuration manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "\n",
    "\n",
    "from cnnClassifier.utils import read_yaml, create_directories     # We do this only after coding in utils.__init__.py , or else it wont work this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "\n",
    "            create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "          config = self.config.data_ingestion\n",
    "\n",
    "          create_directories([config.root_dir])\n",
    "\n",
    "          data_ingestion_config = DataIngestionConfig(\n",
    "                root_dir= config.root_dir,\n",
    "                source_URL= config.source_URL,\n",
    "                local_data_file= config.local_data_file,\n",
    "                unzip_dir= config.unzip_dir\n",
    "          )\n",
    "\n",
    "          return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request    # To dowload the dataset\n",
    "from zipfile import ZipFile         # To unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we are creating the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url = self.config.source_URL,\n",
    "                filename= self.config.local_data_file\n",
    "            )\n",
    "\n",
    "\n",
    "    def _get_updated_list_of_files(self, list_of_files):\n",
    "        return[f for f in list_of_files if f.endswith(\".jpg\") and (\"Cat\" in f or \"Dog\" in f)]   # We only take images and not other files like \"thumb\" or Cat and dog folder\n",
    "    \n",
    "    # the lsit of files, will carry the path, and as per the code it checks wheather the path contains .jpg or Cat or Dog ( the folder name ), \n",
    "    # Thus it will only get the images from the folder and not from the outside.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _preprocess(self, zf: ZipFile, f: str, working_dir: str):\n",
    "        target_filepath = os.path.join(working_dir, f)\n",
    "        if not os.path.exists(target_filepath):\n",
    "            zf.extract(f, working_dir)                  ## But for this code to function properly we need to create working dir before right? Have we ever created that ?\n",
    "\n",
    "        if os.path.getsize(target_filepath) == 0:\n",
    "            os.remove(target_filepath)\n",
    "\n",
    "\n",
    "    def unzip_and_clean(self):\n",
    "        with ZipFile(file= self.config.local_data_file, mode= \"r\") as zf:\n",
    "            list_of_files= zf.namelist()\n",
    "            updated_list_of_files= self._get_updated_list_of_files(list_of_files)\n",
    "\n",
    "            for f in updated_list_of_files:\n",
    "                self._preprocess(zf, f, self.config.unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/harik/Desktop/All Folder/PGDA/Interships & Projects/NLP/End-to-End Workflow/cnnClassifier\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /c/Users/harik/Desktop/All Folder/PGDA/Interships & Projects/NLP/End-to-End Workflow/cnnClassifier/research\n",
    "\n",
    "# Here we need to chnage the path to our root directory, that is cnnClassifier, for that we use os.chdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\harik\\\\Desktop\\\\All Folder\\\\PGDA\\\\Interships & Projects\\\\NLP\\\\End-to-End Workflow\\\\cnnClassifier\\\\research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")   # This will go back one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/harik/Desktop/All Folder/PGDA/Interships & Projects/NLP/End-to-End Workflow/cnnClassifier\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-21 11:06:36,482: INFO: common: yaml file: config\\config.yaml loaded succesfully]\n",
      "[2023-09-21 11:06:36,482: INFO: common: yaml file: params.yaml loaded succesfully]\n",
      "[2023-09-21 11:06:36,482: INFO: common: created directory at: artifacts]\n",
      "[2023-09-21 11:06:36,498: INFO: common: created directory at: artifacts/data_ingestion]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config= ConfigurationManager()\n",
    "    data_ingestion_config= config.get_data_ingestion_config()\n",
    "    data_ingestion= DataIngestion(config= data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.unzip_and_clean()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did all these in this ipnyb file rather than hard coding it in the entity or components, to check if this all works well. ans after the confirmation of that we procedd in writing hte code in a modular way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnncls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
